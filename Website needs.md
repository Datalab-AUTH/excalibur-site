# EXCALIBUR WEBSITE

**RED:** Suggested tabs (structured) \- buttons  
**BLACK:** Suggested text you can add as is in each tab. The text in “” can just be pasted, you can just modify how you present it.  
**ORANGE:** Notes/Sources used  
**BLUE:** Extra material  
\_\_\_

# TOP Aspects

- ### Home

- ### About
  - #### Project

    “The EXCALIBUR project is implemented under the Hellenic Foundation for Research and Innovation (HFRI / ELIDEK) through the call “Basic Research Financing (Horizontal support for all Sciences)”, which is part of Component 4.5 “Promoting Research and Innovation” of the National Recovery and Resilience Plan “Greece 2.0”, funded by the European Union – NextGenerationEU.  
    In response to the growing need for **trustworthy and responsible artificial intelligence**, EXCALIBUR is structured around **three core components**:

- **Framework**

  A research-driven framework that leverages **Large Language Models (LLMs)** as advanced, **model-agnostic explainers and fairness evaluators**, integrating insights from established explainability and fairness approaches into **clear, human-understandable outputs**.

- **Toolset**

  An **open-source toolset and visualization platform** that embeds the framework into real AI pipelines and presents explanations and fairness reports in a **transparent, user-friendly way**, enabling human insight, interaction, and feedback.

- **Evaluation & Case Studies**

  A two-track validation approach combining **in-lab experimentation** for method development and fine-tuning with **in-the-wild case studies** involving stakeholders, assessing usability, trust, clarity, and overall impact through iterative evaluation.

  **The Key Pillars of EXCALIBUR**

- **Regulatory-to-technical mapping**

  The systematic translation of **Trustworthy AI principles and regulatory requirements** into concrete technical specifications and ethical guidelines that shape the framework and platform design.

- **Model-agnostic explainability and fairness, powered by LLMs**

  LLM-based components that produce **human-like explanations and contextual fairness interpretations** across tasks and metrics, supporting the identification and understanding of potential sources of bias in data and models.

- **Open tools and stakeholder-driven validation**

  An **open infrastructure** for reuse (covering code, tools, and platform components) combined with **continuous evaluation involving researchers and non-expert users**, ensuring practical usefulness and societal relevance.”

  Note: Source is [HFRI \- Hellenic Foundation for Research & Innovation](https://www.elidek.gr/en/2022/10/06/basic-research-financing-horizontal-support-for-all-sciences-national-recovery-and-resilience-plan-greece-2-0/) which is summarized.
  - #### Objectives

        Source for the text could be: [HFRI \- Hellenic Foundation for Research & Innovation](https://www.elidek.gr/en/objectives/)  (pasted below:)
        The Hellenic Foundation for Research and Innovation is a new institution through which a profound reforming effort is being undertaken in the field of Research and Innovation in the country.

    The Organization supports unrestricted research (the systematic inquiry born of scientific curiosity) and new researchers by providing scholarships for doctoral candidates, as well as research projects for post-doctoral students, Researchers and Faculty Members.
    Through H.F.R.I., the research and academic community is, for the first time, actively involved in shaping the country’s research and innovation policy without thematic or geographical exclusions, but with the sole criterion of scientific quality and excellence.
    H.F.R.I. was created out of the vital need to support young scientists and as a necessary tool in reversing the outflow of outstanding scientists abroad. Indeed, one of H.F.R.I.’s key goals is to impede the scientific and economic haemorrhage that the loss of gifted Greek researchers entails.

In order to achieve its goals, H.F.R.I.:
• Grants scholarships for doctoral dissertations and post-doctoral studies
• Funds high quality research projects in which post-graduate students, researchers and faculty members are principal investigators
• Finances the acquisition of research equipment
• Enables Universities, TEIs, research and technology stakeholders, to access innovative research program financing
• Supports the creation and operation of start-ups in order to utilize research results

- #### Methodological Approach

  “The methodological approach of EXCALIBUR is structured as an end-to-end strategy for **democratizing trustworthy and responsible AI**, by combining regulatory mapping, method development with Large Language Models (LLMs), tool building, and stakeholder-driven evaluation.  
  The project begins by **translating Trustworthy AI principles into actionable technical requirements**, with emphasis on **transparency, fairness, and accountability**, while also specifying **human-centric needs** (human oversight, societal well-being, safety) and establishing **ethical and data governance guidelines** to ensure GDPR-aligned experimentation.  
  Building on this foundation, EXCALIBUR designs a **model-agnostic LLM-based framework** with two core components: (i) an **explainability module** that learns from diverse XAI methods (e.g., LIME-like to more advanced techniques) to generate human-readable explanations, and (ii) a **fairness evaluation module** that computes and interprets a broad set of fairness metrics and uses the LLM to explain their meaning in context and help uncover potential sources of bias in data and models.  
  The framework is then validated through **two complementary experimentation tracks** in the wearable domain: **in-lab evaluation** using baseline AI models built on public wearable datasets, and **in-the-wild case studies** that involve non-expert stakeholders in iterative rounds to assess usability, trust, clarity of explanations, and usefulness of fairness reports. This process follows a citizen-science-inspired approach to ensure continuous feedback and real-world relevance.  
  Finally, EXCALIBUR delivers an **open-source toolset and visualization platform** (e.g., a Python library plus a web-based interface) that integrates the framework into real AI pipelines, presents results in a human-friendly way, supports user intervention and feedback, and applies standard security and privacy practices for safe deployment.”  
  Source: This is basically a summary of the Methodology of part B2.1: [Final submission files \- Google Drive](https://drive.google.com/drive/folders/1r5Qohwpdao6AE8W8lfoHdG8y2wR_mQsD)

- ### Research & Outputs
  - #### Publications

  - #### Software & Tools

    Note: Needed because of WP4: “Open-source **toolset**/platform”, Deliverables D4.1, D4.2, plus GitHub explicitly mentioned in WP1

- #### Citizen Science / Case Studies

  We need it because of WP5, since we mention Explicit Citizen Science (CS) approach \+ in-the-wild experimentation

We will include: Description of in-lab vs in-the-wild studies, Stakeholder involvement, **Possibly a “Get involved” call later**

\_\_\_

# BOTTOM Aspects

- ##### Contact

  \~etc (up to you)

- **At the bottom of the page you can add:**  
  “This project is funded by the General Secretariat for Research and Technology (GSRT) and the Hellenic Foundation for Research and Innovation (HFRI), under the National Recovery and Resilience Plan “Greece 2.0”, funded by the European Union – NextGenerationEU.”

## Extra Material

### **Useful links (of ELIDEK)** [Main ΕΛΙΔΕΚ website](https://www.elidek.gr/en/homepage/)

[Facebook](https://www.facebook.com/ELIDEKgr/)

[Twitter](https://x.com/ELIDEK_HFRI)

[Linkedin](https://www.linkedin.com/company/hellenic-foundation-for-research-and-innovation/)

### **Logos**

[**logos \- Google Drive**](https://drive.google.com/drive/folders/1Hm-1VteRols8z6dHVmErpfIVWbmPwETo)
